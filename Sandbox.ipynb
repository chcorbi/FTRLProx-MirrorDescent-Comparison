{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow the Regularized Leader and Mirror Descent\n",
    "Charles, Khaled, François, Camille, Nicolas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As those datasets are heavy, choose only one to load"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "def loading_dataset(filename):\n",
    "    data = load_svmlight_file(filename)\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X, y = loading_dataset(\"Datasets/news20.binary\")\n",
    "y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove zeros entries\n",
    "nnz_entries = np.unique(X.nonzero()[0])\n",
    "X = X[nnz_entries]\n",
    "y = y[nnz_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19954x1355191 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9097916 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: DescribeResult(nobs=19954, minmax=(0.0, 1.0), mean=0.49939861681868297, variance=0.25001216776433743, skewness=0.0024055344652483732, kurtosis=-1.9999942134039366)\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "source": [
    "from scipy import stats\n",
    "print ('y:', stats.describe(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Useful tools"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": null,
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": null,
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nnz_fraction(w):\n",
    "    ''' Compute sparsity fraction in a dictionnary '''\n",
    "    a = np.array([i for i in w.values()])\n",
    "    return np.sum(a != 0)/a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    ''' Sigmoid function'''\n",
    "    return 1./ (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(y, p):\n",
    "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
    "    return -np.log(p) if y == 1 else -np.log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regularized Dual Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RDA (BaseEstimator):\n",
    "    '''\n",
    "    Regularized Dual Averaging\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FOBOS composite mirror descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FOBOS (BaseEstimator):\n",
    "    '''\n",
    "    FOBOS composite mirror descent\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Follow-The-Regularized-Leader Proximal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FollowTheRegularizedLeaderProximal (BaseEstimator):\n",
    "    '''\n",
    "    Follow The Regularied Leader Proximal\n",
    "    minimizes iteratively with an adaptive combination of L2 and L1 norms.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, alpha=1., beta=1., lbda1=1., lbda2=1., verbose=1):\n",
    "        # Learning rate's proportionality constant.\n",
    "        self.alpha = alpha\n",
    "        # Learning rate parameter.\n",
    "        self.beta = beta\n",
    "        # L1 regularization parameter.\n",
    "        self.lbda1 = lbda1\n",
    "        # L2 regularization parameter.\n",
    "        self.lbda2 = lbda2\n",
    "        \n",
    "        #Initialize weights parameters\n",
    "        self.z = None\n",
    "        self.n = None\n",
    "        \n",
    "        # Loss initialization\n",
    "        self.log_likelihood = 0\n",
    "        self.loss = []\n",
    "        \n",
    "        self.verbose=verbose\n",
    "\n",
    "\n",
    "    def train(self, X, y):\n",
    "        start_time = datetime.now()\n",
    "                       \n",
    "        self.z = [0.] * X.shape[1]\n",
    "        self.n = [0.] * X.shape[1]\n",
    "\n",
    "        y_proba = []\n",
    "\n",
    "        for t in range(X.shape[0]):\n",
    "            # Init weight vector\n",
    "            w = {}\n",
    "\n",
    "            # Init dot product\n",
    "            wtx = 0\n",
    "\n",
    "            # Non-zeros features of X[t]\n",
    "            I = X[t].nonzero()[1]\n",
    "\n",
    "            # Security\n",
    "            if  I.size == 0:\n",
    "                raise \"Error at ligne %d \" %(t+1)\n",
    "                continue\n",
    "\n",
    "            # Update weight\n",
    "            for i in I:\n",
    "                if self.z[i] <= self.lbda1:\n",
    "                    w[i] = 0\n",
    "                else:\n",
    "                    sign = 1. if self.z[i] >= 0 else -1.\n",
    "                    w[i] = - (self.z[i] - sign * self.lbda1) / ((self.beta + np.sqrt(self.n[i])) / self.alpha + self.lbda2)\n",
    "\n",
    "                # Compute dot product\n",
    "                wtx += w[i] * X[t,i] \n",
    "\n",
    "            # Predict output probability\n",
    "            p = sigmoid(wtx)\n",
    "\n",
    "            # Update weights parameters\n",
    "            for i in I:\n",
    "                # Compute gradient of loss w.r.t wi\n",
    "                g_i = (p - y[t]) * X[t,i]\n",
    "\n",
    "                # Update sigma_i\n",
    "                sigma_i = (np.sqrt(self.n[i] + g_i * g_i) - np.sqrt(self.n[i])) / self.alpha\n",
    "\n",
    "                # Update weights parameters\n",
    "                self.z[i] += g_i - sigma_i * w[i]\n",
    "                self.n[i] += g_i * g_i\n",
    "\n",
    "            # Compute loss\n",
    "            self.log_likelihood += log_loss(y[t], p)\n",
    "\n",
    "            # Append to the loss list.\n",
    "            self.loss.append(self.log_likelihood)\n",
    "\n",
    "            # Print all the current information\n",
    "            if (self.verbose==1 and t%500==0):\n",
    "                print('Training Samples: {0:9} | ' 'Loss: {1:11.2f}'\n",
    "                  .format(t, self.log_likelihood, (datetime.now() - start_time).seconds))\n",
    "\n",
    "            # Add proba\n",
    "            y_proba.append(p)\n",
    "            \n",
    "        return w, y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "FTRL = FollowTheRegularizedLeaderProximal()"
=======
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentatives d'implémentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OnlineSolver():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def iterate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RDASolver(OnlineSolver):\n",
    "    def __init__(self, w_dim, psi, aux, betas):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            w_dim (int): the dimension of the vector on which we want to minimize a function\n",
    "            psi (func): penalization function (input: vector of shape (w_dim, ), output: float)\n",
    "            aux (func): auxiliary function\n",
    "            betas (iterator): non-negative non-decreasing series of float numbers\n",
    "        \"\"\"\n",
    "        self._t = 1\n",
    "        self._gBar = csr_matrix((1, w_dim))\n",
    "        self.psi = psi\n",
    "        self.aux = aux\n",
    "        self.betas = betas\n",
    "        w, _, _ = fmin_l_bfgs_b(self.aux, np.zeros(w_dim), approx_grad=True)\n",
    "        self.w = csr_matrix(w)\n",
    "    \n",
    "    def iterate(self, ft, gt=None):\n",
    "        if gt is None:\n",
    "            raise NotImplementedError(\"Should compute a subgradient of the loss function at time t\")\n",
    "            \n",
    "        self._gBar = (self._t - 1) / self._t * self._gBar + 1 / self._t * gt\n",
    "        w_, _, _ = fmin_l_bfgs_b(\n",
    "            lambda w: (np.dot(self._gBar, w) + self.psi(w) + next(self.betas) / self._t * self.aux(w)), \n",
    "            self.w,\n",
    "            approx_grad=True\n",
    "        )\n",
    "        self.w = csr_matrix(w_)\n",
    "        self._t += 1\n",
    "        return self.w\n",
    "    \n",
    "    def status(self):\n",
    "        data = {\"t\": self._t, \"w\": self.w, \"gBar\": self._gBar}\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IterSqrt():\n",
    "    \"\"\"This iterator returns the series of the square roots of natural integers (from 1).\"\"\"\n",
    "    def __init__(self):\n",
    "        self.t = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.t += 1\n",
    "        return np.sqrt(self.t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regL1 = lambda lbda: (lambda x: lbda * np.linalg.norm(x, ord=1))  # usage: reg = lambda(1.0) <-- function of x"
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples:         0 | Loss:        0.69\n",
      "Training Samples:       500 | Loss:      158.37\n"
     ]
    }
   ],
   "source": [
    "w, y_proba = FTRL.train(X[:1000,:],y[:1000])"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regL2 = lambda gamma: (lambda x: 1 / 2 * gamma * np.linalg.norm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(theta, x, y):\n",
    "    return np.log(1 + np.exp(- y * theta.dot(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = loading_dataset(\"Datasets/rcv1_train.binary\")"
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996996996996997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y[:1000], y_proba)"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.shape"
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039097744360902256"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnz_fraction(w)"
   ]
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rda = RDASolver(w_dim=X.shape[1], psi=regL1(1.0), aux=regL2(1.0), betas=IterSqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    loss = lambda theta: logloss(theta, X[i], y[i])\n",
    "    subgrad = - y[i] * np.exp(- y[i] * rda.w.dot(X[i])) * X[i] / (1 + np.exp(- y[i] * rda.w.dot(X[i])))\n",
    "    rda.iterate(loss, subgrad)\n",
    "    print(rda.status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = csr_matrix((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S[0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = iter(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
>>>>>>> c6b52421464cc0c5c6fa1f69b8157c37282c73e3
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
